{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alissanh/dotfiles/blob/master/mnist_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IL1CUZn7-_QT"
      },
      "source": [
        "# MNIST Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8Mzydwx-_QV"
      },
      "source": [
        "üéØ <b><u>Exercise objectives</u></b>\n",
        "- Understand the *MNIST* dataset \n",
        "- Design your first **Convolutional Neural Network** (*CNN*) and answer questions such as:\n",
        "    - what are *Convolutional Layers*? \n",
        "    - how many *parameters* are involved in such a layer?\n",
        "- Train this CNN on images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPUF4gwp-_Qb"
      },
      "source": [
        "üöÄ <b><u>Let's get started!</u></b>\n",
        "\n",
        "Imagine that we are  back in time into the 90's.\n",
        "You work at a *Post Office* and you have to deal with an enormous amount of letters on a daily basis. How could you automate the process of reading the ZIP Codes, which are a combination of 5 handwritten digits? \n",
        "\n",
        "This task, called the **Handwriting Recognition**, used to be a very complex problem back in those days. It was solved by *Bell Labs* (among others) where one of the Deep Learning gurus, [*Yann Le Cun*](https://en.wikipedia.org/wiki/Yann_LeCun), used to work.\n",
        "\n",
        "From [Wikipedia](https://en.wikipedia.org/wiki/Handwriting_recognition):\n",
        "\n",
        "> Handwriting recognition (HWR), also known as Handwritten Text Recognition (HTR), is the ability of a computer to receive and interpret intelligible handwritten input from sources such as paper documents, photographs, touch-screens and other devices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFVQfDD3-_Qc"
      },
      "source": [
        "![Number recognition](recognition.gif)\n",
        "\n",
        "*Note: The animation above is just here to help you visualize what happens with the different images: <br/> $\\rightarrow$ For each image, once the CNN is trained, it will predict what digit is written. The inputs are the different digits and not one animation/video!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oY6bqknv-_Qc"
      },
      "source": [
        "ü§î <b><u>How does this CNN work ?</u></b>\n",
        "\n",
        "- *Inputs*: Images (_each image shows a handwritten digit_)\n",
        "- *Target*: For each image, you want your CNN model to predict the correct digit (between 0 and 9)\n",
        "    - It is a **multi-class classification** task (more precisely a 10-class classification task since there are 10 different digits).\n",
        "\n",
        "üî¢ To improve the capacity of the Convolutional Neural Network to read these numbers, we need to feed it with many images representing handwritten digits. This is why the üìö [**MNIST dataset**](http://yann.lecun.com/exdb/mnist/) *(Mixed National Institute of Standards and Technology)* was created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s3gEB2xu-_Qd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REkt8qg4-_Qd"
      },
      "source": [
        "## (1) The `MNIST` Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Hu4QE54-_Qd"
      },
      "source": [
        "üìö Tensorflow/Keras offers multiple [**datasets**](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) to play with:\n",
        "- *Vectors*: `boston_housing` (regression)\n",
        "- *Images* : `mnist`, `fashion_mnist`, `cifar10`, `cifar100` (classification)\n",
        "- *Texts*: `imbd`, `reuters` (classification/sentiment analysis)\n",
        "\n",
        "\n",
        "üíæ You can **load the MNIST dataset** with the following commands:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyOWOhxy-_Qe",
        "outputId": "d8af18a3-c63d-400c-ae03-2ba847663416"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(((60000, 28, 28), (60000,)), ((10000, 28, 28), (10000,)))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from tensorflow.keras import datasets\n",
        "\n",
        "\n",
        "# Loading the MNIST Dataset...\n",
        "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data(path=\"mnist.npz\")\n",
        "\n",
        "# The train set contains 60 000 images, each of them of size 28x28\n",
        "# The test set contains 10 000 images, each of them of size 28x28\n",
        "(X_train.shape, y_train.shape), (X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFMqxQQC-_Qe"
      },
      "source": [
        "### (1.1) Exploring the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmVbTJnq-_Qe"
      },
      "source": [
        "‚ùì **Question: Let's have look at some handwritten digits of this MNIST dataset.** ‚ùì\n",
        "\n",
        "üñ® Print some images from the *train set*.\n",
        "\n",
        "<details>\n",
        "    <summary><i>Hints</i></summary>\n",
        "\n",
        "üí°*Hint*: use the `imshow` function from `matplotlib` with `cmap = \"gray\"`\n",
        "\n",
        "ü§® Note: if you don't specify this *cmap* argument, the weirdly displayed colors are just Matplotlib defaults...\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "vZPiyhHJ-_Qf",
        "outputId": "3e0f8001-09ad-4b93-ec45-3e08ee0bf0dd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fig, axs = plt.subplots(3,3, figsize=(8,8))\n",
        "axs[0,0].imshow(X_train[0], cmap='gray')\n",
        "axs[0,1].imshow(X_train[1], cmap='gray')\n",
        "axs[0,2].imshow(X_train[2], cmap='gray')\n",
        "axs[1,0].imshow(X_train[3], cmap='gray')\n",
        "axs[1,1].imshow(X_train[4], cmap='gray')\n",
        "axs[1,2].imshow(X_train[5], cmap='gray')\n",
        "axs[2,0].imshow(X_train[6], cmap='gray')\n",
        "axs[2,1].imshow(X_train[7], cmap='gray')\n",
        "axs[2,2].imshow(X_train[8], cmap='gray');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XNvH68Y-_Qf"
      },
      "source": [
        "### (1.2) Image Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyQ-P1ok-_Qf"
      },
      "source": [
        "‚ùóÔ∏è **Neural Networks converge faster when the input data is somehow normalized** ‚ùóÔ∏è\n",
        "\n",
        "üë©üèª‚Äçüè´ How do we proceed for Convolutional Neural Networks ?\n",
        "* The `RBG` intensities are coded between 0 and 255. \n",
        "* We can simply divide the input data by the maximal value 255 to have all the pixels' intensities between 0 and 1 üòâ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OBEM3QA-_Qf"
      },
      "source": [
        "‚ùì **Question ‚ùì As a first preprocessing step, please normalize your data.** \n",
        "\n",
        "Don't forget to do it both on your train data and your test data.\n",
        "\n",
        "(*Note: you can also center your data, by subtracting 0.5 from all the values, but it is not mandatory*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "id": "W1DKfaIr-_Qf"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Normalization\n",
        "\n",
        "normal = Normalization()\n",
        "normal.adapt(X_train)\n",
        "X_train = normal(X_train)\n",
        "X_test = normal(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlFBCci7-_Qf"
      },
      "source": [
        "### (1.3) Inputs' dimensionality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmXeSqRg-_Qg",
        "outputId": "e4add507-4407-4d53-8d49-2f9c107ee8be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkxuhFUo-_Qg"
      },
      "source": [
        "üëÜ Remember that you have 60,000 training images and 10,000 test images, each of size $(28, 28)$. However...\n",
        "\n",
        "> ‚ùóÔ∏è  **`Convolutional Neural Network models need to be fed with images whose last dimension is the number of channels`.**  \n",
        "\n",
        "> üßëüèª‚Äçüè´ The shape of tensors fed into ***ConvNets*** is the following: `(NUMBER_OF_IMAGES, HEIGHT, WIDTH, CHANNELS)`\n",
        "\n",
        "üïµüèªThis last dimension is clearly missing here. Can you guess the reason why?\n",
        "<br>\n",
        "<details>\n",
        "    <summary><i>Answer<i></summary>\n",
        "        \n",
        "* All these $60000$ $ (28 \\times 28) $ pictures are black-and-white $ \\implies $ Each pixel lives on a spectrum from full black (0) to full white (1).\n",
        "        \n",
        "    * Theoretically, you don't need to know the number of channels for a black-and-white picture since there is only 1 channel (the \"whiteness\" of \"blackness\" of a pixel). However, it is still mandatory for the model to have this number of channels explicitly stated.\n",
        "        \n",
        "    * In comparison, colored pictures need multiple channels:\n",
        "        - the RGB system with 3 channels (<b><span style=\"color:red\">Red</span> <span style=\"color:green\">Green</span> <span style=\"color:blue\">Blue</span></b>)\n",
        "        - the CYMK system  with 4 channels (<b><span style=\"color:cyan\">Cyan</span> <span style=\"color:magenta\">Magenta</span> <span style=\"color:yellow\">Yellow</span> <span style=\"color:black\">Black</span></b>)\n",
        "        \n",
        "        \n",
        "</details>        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2bA3WbC-_Qg"
      },
      "source": [
        "‚ùì **Question: expanding dimensions** ‚ùì\n",
        "\n",
        "* Use the **`expand_dims`** to add one dimension at the end of the training data and test data.\n",
        "\n",
        "* Then, print the shapes of `X_train` and `X_test`. They should respectively be equal to $(60000, 28, 28, 1)$ and $(10000, 28, 28, 1)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WHQ_gqxY-_Qg"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.backend import expand_dims\n",
        "\n",
        "X_train = expand_dims(X_train)\n",
        "X_test = expand_dims(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qeUFEDY-_Qg",
        "outputId": "3a7e5865-368c-467d-ac8c-3fd4754caf5b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([60000, 28, 28, 1]), TensorShape([10000, 28, 28, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFMV6co_-_Qg"
      },
      "source": [
        "### (1.4) Target encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9tpvsnD-_Qh"
      },
      "source": [
        "One more thing to for a multiclass classification task in Deep Leaning:\n",
        "\n",
        "üëâ _\"one-hot-encode\" the categories*_\n",
        "\n",
        "‚ùì **Question: encoding the labels** ‚ùì \n",
        "\n",
        "* Use **`to_categorical`** to transform your labels. \n",
        "* Store the results into two variables that you can call **`y_train_cat`** and **`y_test_cat`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Bf-O7s2E-_Qh"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vFxEYOUh-_Qh"
      },
      "outputs": [],
      "source": [
        "# Quick check that you correctly used to_categorical\n",
        "assert(y_train_cat.shape == (60000,10))\n",
        "assert(y_test_cat.shape == (10000,10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paDR3lHm-_Qh"
      },
      "source": [
        "The data is now ready to be used. ‚úÖ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqEsmA6K-_Qh"
      },
      "source": [
        "## (2) The Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOZc_fnc-_Qh"
      },
      "source": [
        "### (2.1) Architecture and compilation of a CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ikg9GvCc-_Qh"
      },
      "source": [
        "\n",
        "‚ùì **Question: CNN Architecture and compilation** ‚ùì\n",
        "\n",
        "Now, let's build a <u>Convolutional Neural Network</u> that has: \n",
        "\n",
        "\n",
        "- a `Conv2D` layer with 8 filters, each of size $(4, 4)$, an input shape suitable for your task, the `relu` activation function, and `padding='same'`\n",
        "- a `MaxPool2D` layer with a `pool_size` equal to $(2, 2)$\n",
        "- a second `Conv2D` layer with 16 filters, each of size $(3, 3)$, and the `relu` activation function\n",
        "- a second `MaxPool2D` layer with a `pool_size` equal to $(2, 2)$\n",
        "\n",
        "\n",
        "- a `Flatten` layer\n",
        "- a first `Dense` layer with 10 neurons and the `relu` activation function\n",
        "- a last (predictive) layer that is suited for your task\n",
        "\n",
        "In the function that initializes this model, do not forget to include the <u>compilation of the model</u>, which:\n",
        "* optimizes the `categorical_crossentropy` loss function,\n",
        "* with the `adam` optimizer, \n",
        "* and the `accuracy` as the metrics\n",
        "\n",
        "(*Note: you could add more classification metrics if you want but the dataset is well balanced!*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XDYYMWCt-_Qi"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "\n",
        "\n",
        "def initialize_model():\n",
        "\n",
        "    model = models.Sequential()\n",
        "\n",
        "    ### First Convolution & MaxPooling\n",
        "    model.add(layers.Conv2D(8, (4,4), activation='relu', padding='same',input_shape=(28,28,1)))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "    \n",
        "    ### Second Convolution & MaxPooling\n",
        "    model.add(layers.Conv2D(16, (3,3), activation='relu'))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "    \n",
        "    ### Flattening\n",
        "    model.add(layers.Flatten())\n",
        "    \n",
        "    ### One Fully Connected layer - \"Fully Connected\" is equivalent to saying \"Dense\"\n",
        "    model.add(layers.Dense(10, activation='relu'))\n",
        "    \n",
        "    ### Last layer - Classification Layer with 10 outputs corresponding to 10 digits\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    \n",
        "    ### Model compilation\n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer='adam',\n",
        "        metrics='accuracy'\n",
        "    )\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVk9vo6r-_Qi"
      },
      "source": [
        "‚ùì **Question: number of trainable parameters in a convolutional layer** ‚ùì \n",
        "\n",
        "How many trainable parameters are there in your model?\n",
        "1. Compute them with ***model.summary( )*** first\n",
        "2. Recompute them manually to make sure you properly understood ***what influences the number of weights in a CNN***."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhicWgGC-_Qi",
        "outputId": "938ae65a-4829-4d02-b8ba-77388938dabe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 8)         136       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 8)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 12, 12, 16)        1168      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 6, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 576)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                5770      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,184\n",
            "Trainable params: 7,184\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = initialize_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uMsITzW-_Qi"
      },
      "source": [
        "### (2.2) Training a CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz1j1ZYc-_Qi"
      },
      "source": [
        "‚ùì **Question: training a CNN** ‚ùì \n",
        "\n",
        "Initialize your model and fit it on the train data. \n",
        "- Do not forget to use a **Validation Set/Split** and an **Early Stopping criterion**. \n",
        "- Limit yourself to 5 epochs max in this challenge, just to save some precious time for the more advanced challenges!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "oiLlN6Dm-_Qi"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model = initialize_model()\n",
        "es = EarlyStopping()\n",
        "history = model.fit(X_train, y_train_cat,\n",
        "                    epochs=5,\n",
        "                    validation_split=0.3,\n",
        "                    batch_size=16,\n",
        "                    verbose=0,\n",
        "                    callbacks=[es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiOdABIL-_Qi",
        "outputId": "7bab6dac-ff52-4295-976f-6ddd0224373d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0769 - accuracy: 0.9767\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0769164115190506, 0.9767000079154968]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "model.evaluate(X_test, y_test_cat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tx3ytCju-_Qj"
      },
      "source": [
        "‚ùì **Question: How many iterations does the CNN perform per epoch** ‚ùì\n",
        "\n",
        "_Note: it has nothing to do with the fact that this is a CNN. This is related to the concept of forward/backward propagation already covered during the previous lecture on optimizers, fitting, and losses üòâ_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "challengify"
        ],
        "id": "vqR1UrIO-_Qj"
      },
      "source": [
        "- 60000/16 = 3750 minibatches\n",
        "- 3750 x 0.7 = 2625 minibatches for train_loss\n",
        "- 3750 - 2625 = 1125 minibatches for val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2CWBQGz-_Qj"
      },
      "source": [
        "<details>\n",
        "    <summary><i>Answer</i></summary>\n",
        "\n",
        "With `verbose = 1` when fitting your model, you have access to crucial information about your training procedure.\n",
        "    \n",
        "Remember that we've just trained our CNN model on $60000$ training images\n",
        "\n",
        "If the chosen batch size is 32: \n",
        "\n",
        "* For each epoch, we have $ \\large \\lceil \\frac{60000}{32} \\rceil = 1875$ minibatches <br/>\n",
        "* The _validation_split_ is equal to $0.3$ - which means that within one single epoch, there are:\n",
        "    * $ \\lceil 1875 \\times (1 - 0.3) \\rceil = \\lceil 1312.5 \\rceil = 1313$ batches are used to compute the `train_loss` \n",
        "    * $ 1875 - 1312 = 562 $ batches are used to compute the `val_loss`\n",
        "    * **The parameters are updated 1313 times per epoch** as there are 1313 forward/backward propagations per epoch !!!\n",
        "\n",
        "\n",
        "üëâ With so many updates of the weights within one epoch, you can understand why this CNN model converges even with a limited number of epochs.\n",
        "\n",
        "</details>    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4J7j4fD-_Qj"
      },
      "source": [
        "### (2.3) Evaluating its performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvhvPH-d-_Qj"
      },
      "source": [
        "‚ùì **Question: Evaluating your CNN** ‚ùì \n",
        "\n",
        "What is your **`accuracy on the test set?`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIWXVg2V-_Qj",
        "outputId": "e62162c9-41c3-4f40-fd12-354a9e790b91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0769 - accuracy: 0.9767\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9767000079154968"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "model.evaluate(X_test, y_test_cat)[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jgk8KQnI-_Qj"
      },
      "source": [
        "üéâ You should already be impressed by your CNN skills! Reaching over 95% accuracy!\n",
        "\n",
        "üî• You solved what was a very hard problem 30 years ago with your own CNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmhFXhs7-_Qj"
      },
      "source": [
        "üèÅ **Congratulations!**\n",
        "\n",
        "üíæ Don't forget to `git add/commit/push` your notebook...\n",
        "\n",
        "üöÄ ... and move on to the next challenge!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit ('lewagon')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "d67595d1c6b2e5ad8f6b1ea188dc9212d1bdbd5f26d336fc7871fdcf521a775c"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}